![text_generation_sampling](https://user-images.githubusercontent.com/58797479/94343512-589f4900-0036-11eb-9481-f2a6e0bba710.png)

# Generate-Text
Using Recurrent Neural Networks it is possible to generate text . We can train the models on large text data ,let the model train on input data  and generate text.<br> 
Here I have tried to generate text ,on a war based ebook using recurrent neural network (character level language model).<br>
You can see this is the generated text -> "these appearances in order to appreciate fully their
remarkable resemblance in character.
at any rate, whether we expect another invasion or not, orate, whether we expect another invasion or not, on the wheel came papious, and for fer deep fluck about the starustity from a man being came. we saw ." This is not quite good ,but its not even bad !! I have trained for 20 epochs only , and on a bit shorter corpus.<br>
<b>The model can be improved by :- </b>
<ol>
  <li>Increasing the input text corpus .</li>
  <li>Training with more no. epochs.</li>
  <li>Increasing the LSTM layers / Adding more neurons.</li>
  <li>Try with different temperatures that suit your requirement!</li>
  </ol>
  

