{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-level-neural-language-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy6ky-61ahb3",
        "outputId": "818c532f-d45d-4776-d88d-aa16a1c4f14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1whzyLSdaof5"
      },
      "source": [
        "path = '/content/drive/My Drive/war.txt'\n",
        "text = open(path, 'r' , errors='ignore').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOmImrf6bJOW",
        "outputId": "04d0494f-a083-4393-f3bb-6f7088291124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import string\n",
        "import re\n",
        "string.punctuation"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swi6HEcFf2bp",
        "outputId": "b0fc7650-7aed-4c74-9c57-a430f620da41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTHE EVE OF THE WAR.\\n\\nNo one would have believed in the last years of the nineteenth century\\nthat th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAT_luB7f-0F"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = text.replace('\\n' ,' ')\n",
        "  tokens = text.split('.')\n",
        "  clean_text= []\n",
        "  for token in tokens:\n",
        "    clean_text.append(re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]' , '' , token))\n",
        "  clean_text = [word.lower() for word in clean_text]\n",
        "  return clean_text  \n",
        "    \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRwotQBNpkqB",
        "outputId": "09069f93-bf6f-495b-a980-18a93bd6b7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(text[:300])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "THE EVE OF THE WAR.\n",
            "\n",
            "No one would have believed in the last years of the nineteenth century\n",
            "that this world was being watched keenly and closely by intelligences\n",
            "greater than mans and yet as mortal as his own; that as men busied\n",
            "themselves about their various concerns they were scrutinised and\n",
            "stud\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbQkUhPjprb"
      },
      "source": [
        "tokens = clean_text(text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0AmhDhUkydW",
        "outputId": "7fd296d7-92b8-46e0-8332-0fc98eb29c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tokens))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj4E1IAarKbs",
        "outputId": "38e4d69a-2425-4105-c566-5ec92610d1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "length = [len(i) for i in tokens]\n",
        "print(max(length))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw0PqagvPuLP",
        "outputId": "17d061a6-b462-4fb4-8751-89e7d6d8b9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "length_df = pd.DataFrame(length , columns=['Length'])\n",
        "print(length_df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Length\n",
            "0      19\n",
            "1     420\n",
            "2     143\n",
            "3      67\n",
            "4     168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA43PS8ohOmd",
        "outputId": "21debf37-3ed7-4c92-a3e3-68e04f6c6d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.hist(length , bins=25)\n",
        "plt.xlabel('Length of Sequences')\n",
        "plt.ylabel('Count Falling in that range')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAFzCAYAAADR6BVMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcZUlEQVR4nO3debQmdX3n8fcHEFC2ZukwDGAaDKMhmSikNRCYRDHJKChoROISJQZlZjQqMRrayUxEk8zBTOKaBINiwMR9QRCMioAm0Qg2iMgioSXNoQnQrbLquIDf+aN+t3jS3r5dTfezdPf7dU6dp+pX9dTzvfd238+t+lX9KlWFJEkA20y7AEnS7DAUJEk9Q0GS1DMUJEk9Q0GS1DMUJEm97aZdwMbYa6+9asmSJdMuQ5I2K1dcccU3q2rxfOs261BYsmQJy5cvn3YZkrRZSXLzutZ5+kiS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1NusR0mddUuWXbhB2688/ZgxVSJJw3ikIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqbTftAjYXS5ZdOO0SJGnsPFKQJPUMBUlSz1CQJPUMBUlSb6yhkGRlkq8luSrJ8ta2R5KLktzYXndv7UnytiQrklyd5NBx1iZJ+nGTOFJ4UlU9rqqWtuVlwMVVdRBwcVsGeCpwUJtOBs6YQG2SpBHTOH10HHBOmz8HeMZI+3uq8yVgUZJ9plCfJG21xh0KBXwmyRVJTm5te1fVbW3+dmDvNr8vcMvIe1e1NknShIz75rUjq+rWJD8BXJTk66Mrq6qS1IbssIXLyQCPfOQjN12lkqTxHilU1a3tdTVwLvAE4I6500LtdXXb/FZg/5G379fa1t7nmVW1tKqWLl68eJzlS9JWZ2yhkGSnJLvMzQO/BlwDnA+c2DY7ETivzZ8PvLBdhXQYcPfIaSZJ0gSM8/TR3sC5SeY+531V9akkXwY+lOQk4GbghLb9J4GjgRXAd4EXjbE2SdI8xhYKVXUT8Nh52r8FPHme9gJeNq56JEnr5x3NkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6o17QDxtgCXLLtyg7VeefsyYKpG0tfJIQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkSb1BoZDkyCQvavOLkxww3rIkSdOw3lBI8jrgVOC1relhwN+NsyhJ0nQMOVJ4JnAs8B2Aqvo3YJdxFiVJmo4hofCDqiqgAJLsNN6SJEnTMiQUPpTkr4FFSV4CfBZ459APSLJtkq8kuaAtH5DksiQrknwwyfatfYe2vKKtX7LhX44kaWOsNxSq6s+AjwAfBR4N/GFVvX0DPuOVwPUjy28E3lxVPwXcCZzU2k8C7mztb27bSZImaNDVR1V1UVW9pqpeXVUXDd15kv2AY4B3teUAR9GFDMA5wDPa/HFtmbb+yW17SdKEDLn66N4k96w13ZLk3CQHruftbwF+H/hRW94TuKuq7m/Lq4B92/y+wC0Abf3dbfu16zk5yfIky9esWbPeL1CSNNyQI4W3AK+h+6W9H/Bq4H3AB4B3r+tNSZ4GrK6qKzZBnb2qOrOqllbV0sWLF2/KXUvSVm+7AdscW1WPHVk+M8lVVXVqkv+5wPuOAI5NcjSwI7Ar8Fa6Duvt2tHAfsCtbftbgf2BVUm2A3YDvrWBX48kaSMMOVL4bpITkmzTphOA77V1ta43VdVrq2q/qloCPAe4pKqeD1wKHN82OxE4r82f35Zp6y9pl8JKkiZkSCg8H3gBsBq4o83/ZpKHA7/zED7zVOBVSVbQ9Rmc1drPAvZs7a8Clj2EfUuSNsJ6Tx9V1U3A09ex+p+GfEhVfQ743Mj+njDPNt8Dnj1kf5Kk8VhvKCRZDLwEWDK6fVX99vjKkiRNw5CO5vOAf6S7k/mB8ZYjSZqmIaHwiKo6deyVSJKmbkhH8wXtslJJ0hZuSCi8ki4Y/l+7m/neJPeMuzBJ0uQNufrIZyfMqCXLLtyg7VeefsyYKpG0pRjSp0CS3YGD6O5MBqCq/mFcRUmSpmPIJakvpjuFtB9wFXAY8M90o51KkrYgQ/sUHg/cXFVPAg4B7hprVZKkqRgSCt9rdxuTZIeq+jrdw3YkSVuYIX0Kq5IsAj4OXJTkTuDm8ZYlSZqGIVcfPbPNnpbkUrohrT811qokSVOxYCgk2Ra4tqoeA1BVn59IVZKkqViwT6GqHgBuSPLICdUjSZqiIX0KuwPXJrkc+M5cY1UdO7aqJElTMSQU/vfYq5AkzYQhHc32I0jSVmLIfQqSpK2EoSBJ6q03FJK8ckibJGnzN+RI4cR52n5rE9chSZoB6+xoTvJc4HnAAUnOH1m1C/DtcRcmSZq8ha4++iJwG7AX8Ocj7fcCV4+zKEnSdKwzFKrqZrqB7w6fXDmSpGka0tF8WJIvJ7kvyQ+SPOAzmiVpyzSko/kvgOcCNwIPB14M/OU4i5IkTceg+xSqagWwbVU9UFV/AzxlvGVJkqZhyNhH302yPXBVkj+l63z2pjdJ2gIN+eX+grbd79CNkro/8KxxFiVJmo4hA+LNPXrze8Drx1uOJGma1hsKSY4ATgN+cnT7qjpwfGVJkqZhSJ/CWcDvAlcAD4y3HEnSNA0Jhbur6u/HXokkaeoWGvvo0DZ7aZL/C3wM+P7c+qq6csy1SZImbKEjhT9fa3npyHwBR236ciRJ07TQ2EdPAkhyYFXdNLouiZ3MkrQFGnKfwkfmafvwpi5EkjR9C/UpPAb4GWC3JL8+smpXYMdxFyZJmryF+hQeDTwNWAQ8faT9XuAl4yxKkjQdC/UpnAecl+TwqvrnCdYkSZqS9fYpGAiStPVwtFNJUs9QkCT1hgyItwPdUNlL+PcD4r1hfGVJkqZhyNhH5wF30w2I9/31bCtJ2owNCYX9qsrHb0rSVmBIn8IXk/znDd1xkh2TXJ7kq0muTfL61n5AksuSrEjywfaoT5Ls0JZXtPVLNvQzJUkbZ0goHAlckeSGJFcn+VqSqwe87/vAUVX1WOBxwFOSHAa8EXhzVf0UcCdwUtv+JODO1v7mtp0kaYKGnD566kPZcVUVcF9bfFib5kZXfV5rP4fuqW5nAMe1eejGW/qLJGn7kSRNwDqPFJLs2mbvXce0Xkm2TXIVsBq4CPgGcFdV3d82WQXs2+b3BW4BaOvvBvacZ58nJ1meZPmaNWuGlCFJGmihI4X30Y19dAXdX/gZWVfAeofPrqoHgMclWQScCzzmoZfa7/NM4EyApUuXehQhSZvQQmMfPa29HrCxH1JVdyW5FDgcWJRku3Y0sB9wa9vsVmB/YFWS7YDdgG9t7GdLkoYb2x3NSRa3IwSSPBz4VeB64FLg+LbZiXT3QQCc35Zp6y+xP0GSJmtIR/NDtQ9wTpJt6cLnQ1V1QZLrgA8k+WPgK8BZbfuzgL9NsgL4NvCcMdYmSZrH2EKhqq4GDpmn/SbgCfO0fw949rjqkSSt35Cxj/aYp/neqvrhGOqRJE3RkD6FK4E1wL8AN7b5lUmuTPLz4yxOkjRZQ0LhIuDoqtqrqvaku5ntAuClwF+NszhJ0mQNCYXDqurTcwtV9Rng8Kr6ErDD2CqTJE3ckI7m25KcCnygLf8GcEe7quhHY6tMkjRxQ44Unkd3k9nH2/TI1rYtcML4SpMkTdp6jxSq6pvAy9exesWmLUeSNE1DLkn9T8Cr+fHHcR41vrIkSdMwpE/hw8A7gHcBD4y3HEnSNA0Jhfur6oyxVyJJmrohHc2fSPLSJPsk2WNuGntlkqSJG3KkMDdy6WtG2gY9T0GStHkZcvXRRj9PQZK0eVhnKCQ5qqouSfLr862vqo+NryxJ0jQsdKTwy8AlwNPnWVeAobCZWbLswg3afuXpx4ypEkmzaqHHcb6uvb5ocuVIkqZpodNHr1rojVX1pk1fjiRpmhY6fbTLxKqQJM2EhU4fvX6ShUiSpm+h00dvW+iNVfWKTV+OJGmaFjp9dMXEqpAkzYSFTh+dM8lCJEnTN2To7MXAqcDBwI5z7Q6dLUlbniED4r0XuB44AHg9sBL48hhrkiRNyZBQ2LOqzgJ+WFWfr6rfBjxKkKQt0JBRUn/YXm9Lcgzwb4BDZ0vSFmhIKPxxkt2A3wPeDuwK/O5Yq5IkTcU6Tx8lORugqi4AnlFV11TVk6rq56vq/EkVKEmanIX6FB47Mv/KcRciSZq+hUKhJlaFJGkmLNSnsF8b6iIj8z2HuZCkLc9CoTD6TObl4y5EkjR9DnMhSeoNuXlNkrSVMBQkSb31hkKSI4a0SZI2f0OOFN4+sE2StJlb6MlrhwO/CCxO8qqRVbsC2467MEnS5C10Ser2wM5tm11G2u8Bjh9nUZKk6VjoktTPA59PcnZV3TzBmiRJUzJklNQdkpwJLBndfnN/8tqSZRdOuwRJmjlDQuHDwDuAdwEPjLccSdI0DQmF+6vqjLFXIkmauiGXpH4iyUuT7JNkj7lp7JVJkiZuyJHCie11dIC8Ag7c9OVIkqZpvaFQVQdMohBJ0vStNxSSvHC+9qp6z3retz/wHmBvuiOLM6vqre3U0wfprmZaCZxQVXcmCfBW4Gjgu8BvVdWVw78USdLGGtKn8PiR6b8ApwHHDnjf/cDvVdXBwGHAy5IcDCwDLq6qg4CL2zLAU4GD2nQyYOe2JE3YkNNHLx9dTrII+MCA990G3Nbm701yPbAvcBzwxLbZOcDngFNb+3uqqoAvJVmUZJ+2H0nSBDyUobO/A2xQP0OSJcAhwGXA3iO/6G+nO70EXWDcMvK2Va1t7X2dnGR5kuVr1qzZsMolSQsa0qfwCbo+AegGwvtp4ENDPyDJzsBHgVOq6p6u66BTVZWk1vnmeVTVmcCZAEuXLt2g90qSFjbkktQ/G5m/H7i5qlYN2XmSh9EFwnur6mOt+Y6500JJ9gFWt/Zbgf1H3r5fa5MkTch6Tx+1gfG+TjdS6u7AD4bsuF1NdBZwfVW9aWTV+Tx478OJwHkj7S9M5zDgbvsTJGmyhjx57QTgcuDZwAnAZUmGDJ19BPAC4KgkV7XpaOB04FeT3Aj8SlsG+CRwE7ACeCfw0g39YiRJG2fI6aM/AB5fVasBkiwGPgt8ZKE3VdU/AVnH6ifPs30BLxtQjyRpTIZcfbTNXCA03xr4PknSZmbIkcKnknwaeH9b/g3g78dXkiRpWobcvPaaJL8OHNmazqyqc8dbliRpGtYZCkl+iu5Gsy+0y0k/1tqPTPKoqvrGpIqUJE3GQn0DbwHumaf97rZOkrSFWSgU9q6qr63d2NqWjK0iSdLULBQKixZY9/BNXYgkafoW6mhenuQlVfXO0cYkLwauGG9ZmgVLll24we9ZefoxY6hE0qQsFAqnAOcmeT4PhsBSYHvgmeMuTJI0eesMhaq6A/jFJE8CfrY1X1hVl0ykMknSxA25T+FS4NIJ1CJJmjKHq5Ak9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVJvu2kXoC3LkmUXbtD2K08/ZkyVSHooPFKQJPUMBUlSz1CQJPUMBUlSb2yhkOTdSVYnuWakbY8kFyW5sb3u3tqT5G1JViS5Osmh46pLkrRu4zxSOBt4ylpty4CLq+og4OK2DPBU4KA2nQycMca6JEnrMLZQqKp/AL69VvNxwDlt/hzgGSPt76nOl4BFSfYZV22SpPlNuk9h76q6rc3fDuzd5vcFbhnZblVrkyRN0NQ6mquqgNrQ9yU5OcnyJMvXrFkzhsokaes16VC4Y+60UHtd3dpvBfYf2W6/1vZjqurMqlpaVUsXL1481mIlaWsz6VA4HzixzZ8InDfS/sJ2FdJhwN0jp5kkSRMytrGPkrwfeCKwV5JVwOuA04EPJTkJuBk4oW3+SeBoYAXwXeBF46pLkrRuYwuFqnruOlY9eZ5tC3jZuGqRJA3jHc2SpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpN7YRkmVhliy7MIN2n7l6ceMqRJJ4JGCJGmEoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSez1PQZsXnL0jj5ZGCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKnnfQraonlfg7RhPFKQJPUMBUlSz1CQJPUMBUlSz1CQJPW8+kga4dVK2toZCtJG2NAQAYNEs81QkCbsoQTJhjB0tDFmqk8hyVOS3JBkRZJl065HkrY2MxMKSbYF/hJ4KnAw8NwkB0+3KknausxMKABPAFZU1U1V9QPgA8BxU65JkrYqs9SnsC9wy8jyKuAXplSLtNkad5/FLNrc+1Fm6YKFWQqFQZKcDJzcFu9LcsND3NVewDc3TVVjtbnUCZtPrda5aU29zrxx0GZTr3OgQXUO/JrX5SfXtWKWQuFWYP+R5f1a279TVWcCZ27shyVZXlVLN3Y/47a51AmbT63WuWlZ56Y17TpnqU/hy8BBSQ5Isj3wHOD8KdckSVuVmTlSqKr7k/wO8GlgW+DdVXXtlMuSpK3KzIQCQFV9EvjkhD5uo09BTcjmUidsPrVa56ZlnZvWVOtMVU3z8yVJM2SW+hQkSVO2VYbCLA2nkeTdSVYnuWakbY8kFyW5sb3u3tqT5G2t7quTHDrBOvdPcmmS65Jcm+SVs1hrkh2TXJ7kq63O17f2A5Jc1ur5YLuYgSQ7tOUVbf2SSdQ5Uu+2Sb6S5IJZrTPJyiRfS3JVkuWtbaZ+7iO1LkrykSRfT3J9ksNnrdYkj27fy7npniSnzEydVbVVTXSd2N8ADgS2B74KHDzFen4JOBS4ZqTtT4FlbX4Z8MY2fzTw90CAw4DLJljnPsChbX4X4F/ohiOZqVrb5+3c5h8GXNY+/0PAc1r7O4D/0eZfCryjzT8H+OCEf/6vAt4HXNCWZ65OYCWw11ptM/VzH6nrHODFbX57YNGs1tpq2Ba4ne6+gZmoc6LfgFmYgMOBT48svxZ47ZRrWrJWKNwA7NPm9wFuaPN/DTx3vu2mUPN5wK/Ocq3AI4Ar6e6M/yaw3dr/Buiudju8zW/XtsuE6tsPuBg4Crig/aefxTrnC4WZ+7kDuwH/uvb3ZRZrHfnMXwO+MEt1bo2nj+YbTmPfKdWyLntX1W1t/nZg7zY/E7W3UxeH0P0VPnO1tlMyVwGrgYvojgzvqqr756mlr7OtvxvYcxJ1Am8Bfh/4UVvec0brLOAzSa5IN6IAzODPHTgAWAP8TTsl964kO81orXOeA7y/zc9EnVtjKGxWqvvTYGYuEUuyM/BR4JSqumd03azUWlUPVNXj6P4SfwLwmCmX9GOSPA1YXVVXTLuWAY6sqkPpRjB+WZJfGl05Kz93uiOoQ4EzquoQ4Dt0p2F6M1Qrrb/oWODDa6+bZp1bYygMGk5jyu5Isg9Ae13d2qdae5KH0QXCe6vqY7NcK0BV3QVcSncaZlGSuftyRmvp62zrdwO+NYHyjgCOTbKSbkTgo4C3zmCdVNWt7XU1cC5d0M7iz30VsKqqLmvLH6ELiVmsFbqQvbKq7mjLM1Hn1hgKm8NwGucDJ7b5E+nO38+1v7BdjXAYcPfI4eZYJQlwFnB9Vb1pVmtNsjjJojb/cLp+j+vpwuH4ddQ5V//xwCXtr7SxqqrXVtV+VbWE7t/gJVX1/FmrM8lOSXaZm6c7B34NM/ZzB6iq24Fbkjy6NT0ZuG4Wa22ey4OnjubqmX6dk+xUmZWJrjf/X+jONf/BlGt5P3Ab8EO6v3ROojtXfDFwI/BZYI+2begeRPQN4GvA0gnWeSTd4ezVwFVtOnrWagV+DvhKq/Ma4A9b+4HA5cAKusP1HVr7jm15RVt/4BT+DTyRB68+mqk6Wz1fbdO1c/9fZu3nPlLv44Dl7ef/cWD3WawV2InuSG+3kbaZqNM7miVJva3x9JEkaR0MBUlSz1CQJPUMBUlSz1CQJPUMBc2MJPeNef+nJHnEpvi8NmrpZ9sol7+x1rrD0o1kelUbqfO0jShbmqiZevKaNGanAH8HfHcT7OsQgOqG01jbOcAJVfXVJNsCj55nG2kmeaSgmZbkUUk+1QZj+8ckj2ntZ7cx5r+Y5KYkx7f2bZL8VRtP/6Ikn0xyfJJXAP8RuDTJpSP7/5N0z174UpK95/n8PZJ8vI1j/6UkP5fkJ+jC5fHtaOBRa73tJ+huSKS6cZiua/vaKd3zMy5vA7Yd19ofnuQD7aji3HaUsbStu2+kluOTnN3mFyf5aJIvt+mI1n5a+4zPte/LK0be/8L2dXw1yd+uZz+/nAfH+//K3F3N2gpM8m5DJ6eFJuC+edouBg5q879AN7wDwNl0d/huQ/dchxWt/Xi653xvA/wH4E7g+LZuJSNDQNPdof30Nv+nwP+a5/PfDryuzR8FXNXmn0i7C3me9/xh+9xzgf8G7Nja/w/wm21+Ed1d9TvRPVPh3a3954D7aXetjn5P2td2dpt/H91AdQCPpBt+BOA04IvADsBedHfNPgz4mfZ5e7Xt9ljPfj4BHNHmd6YN5+205U+ePtLMSjci6y8CH+6GXgK6X3ZzPl5VPwKuG/kr/0jgw6399tGjgnn8gO45BgBX0I2TtLYjgWcBVNUlSfZMsutCdVfVG5K8l26coOfRjXHzxLZ8bJJXt013pPtF/EvA29p7r05y9UL7b34FOHjk+7Jr+34BXFhV3we+n2Q13RDMR9F9X77ZPufb69nPF4A3ta/jY1W1akBN2gIYCppl29A9X2C+8/YA3x+Zzzq2WcgPq2punJcH2IT/H6rqG8AZSd4JrEmyZ6vxWVV1w+i2I7+Q593VyPyOI/PbAIdV1ffm2dfo92V9X9e8+wFOT3Ih3fhWX0jyX6vq6wsVqi2DfQqaWdU9r+Ffkzwb+mfVPnY9b/sC8KzWt7A33V/oc+6le5TohvhH4Pnt858IfLPWeo7E2pIckwd/0x9E94v5Lrqnp718bl2SQ9o2/0B3REGSn6U7hTTnjiQ/nWQb4Jkj7Z8BXj7ymesKzjmXAM9u4USSPRbaT5JHVdXXquqNdCMLz9wzKTQehoJmySOSrBqZXkX3C/mkJHOjdB63nn18lG602evoOoOvpHtKGcCZwKfWc0ppbacBP99O6ZzOg0MbL+QFwA3pnv72t8Dzq+oB4I/ozu9fneTatgxwBrBzkuuBN9CdypqzjO4U1xdpndfNK4ClreP4OuC/L1RQVV0L/Anw+fa9nBv+fF37OSXJNe3r/iHdM4K1FXCUVG1xkuxcVfe1v4ovp+swvX3adQ2V5HPAq6tq+bRr0dbHPgVtiS5I96Cd7YE/2pwCQZo2jxQkST37FCRJPUNBktQzFCRJPUNBktQzFCRJPUNBktT7/3BB+nN0r1mHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3MkUpaYAL7h"
      },
      "source": [
        "# As you can see , there are few tokens whoose length is too low .So they might be noise or Nan values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V-T8lUBQ13i",
        "outputId": "fcc188e6-3474-4204-d516-6515ddefec1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "indices_to_drop = length_df[length_df['Length'] < 30].index\n",
        "print(len(indices_to_drop))\n",
        "indices_to_drop"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,   58,   83,  136,  137,  141,  142,  177,  217,  218,\n",
              "            ...\n",
              "            2826, 2827, 2831, 2832, 2869, 2872, 2882, 2883, 2884, 2886],\n",
              "           dtype='int64', length=237)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9aEwcgTSs46"
      },
      "source": [
        "count = 0\n",
        "for i in indices_to_drop:\n",
        "  tokens.pop(i-count)\n",
        "  count+=1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gagSECn8S8tB",
        "outputId": "e9f0bda5-d268-4e9a-fe4b-9f5e0892f6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8RluKe4S6T3",
        "outputId": "3dd561f6-c1e5-422a-9250-c4f93df66e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "length = [len(i) for i in tokens]\n",
        "print(max(length))\n",
        "length_df = pd.DataFrame(length , columns=['Length'])\n",
        "print(len(length_df[length_df['Length']< 30]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "722\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2QYYHsvUe2v",
        "outputId": "13d3223d-bf74-4687-ce56-9d3b07842226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#fig,ax = plt.figure(figsize=(6,6))\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.hist(length , bins=20)\n",
        "plt.xlabel('Length of Sequences')\n",
        "plt.ylabel('Count Falling in that range')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBYDBHmT_3m6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwbiVrnQQYB6"
      },
      "source": [
        "def save_doc(lines , filename):\n",
        "  # Saving each line on a new line\n",
        "  data = '\\n'.join(lines)\n",
        "  file = open(filename , 'w')\n",
        "  file.write(data)\n",
        "  file.close()\n",
        "  print(\"Done\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb6Rl823ng0c",
        "outputId": "caffbf5b-633c-4fed-c3f7-29ed065c1297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file_name = 'clean_war.txt'\n",
        "save_doc(sequences_2 , file_name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc0-vQ25ZgKR"
      },
      "source": [
        "def load_data(filename):\n",
        "  file = open(filename)\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiNUWwQ9ZYW-"
      },
      "source": [
        "file_name = 'clean_war.txt'\n",
        "doc = load_data(file_name)\n",
        "lines = doc.split('\\n')\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItLC05-ri4ho",
        "outputId": "059239cc-e308-4bb3-fe9d-07f1d5e9e68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  no one would have believed in the last years of the nineteenth century that this world was being watched keenly and closely by intelligences greater than mans and yet as mortal as his own that as men busied themselves about their various concerns they were scrutinised and studied perhaps almost as narrowly as a man with a microscope might scrutinise the transient creatures that swarm and multiply in a drop of water'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MIeInf0al10"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding,Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import random"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwMHlwKoazTY"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv0vbnXca3NE",
        "outputId": "2004c316-1b0d-4697-d052-d364f6a9fb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhqwbWLCa-eb"
      },
      "source": [
        "# Padding sequences\n",
        "max_len = 100 + 1\n",
        "sequences = pad_sequences(sequences , maxlen = max_len , padding= 'pre' , truncating='pre')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epXXMJrGatMg"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X,y = sequences[:,:-1] , sequences[:,-1]\n",
        "y = to_categorical(y , num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUafWi5Ae9NX",
        "outputId": "c9bb1603-1d09-4f00-c906-67e11208c842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(seq_length)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQtq03p00h3n",
        "outputId": "5b2308ee-0bd6-4009-c2be-4ec8d6cd1d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# downloading  pretrained GloVe embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 13:46:56--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-09-27 13:46:56--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-09-27 13:46:57--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.26MB/s    in 6m 29s  \n",
            "\n",
            "2020-09-27 13:53:27 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsxWAMGD0kdw",
        "outputId": "e702f458-4674-4bb5-f711-994e28bfade4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT5kZH2l0iD8"
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4LH5gQ0rZN",
        "outputId": "9fa9ecb1-a141-4014-e217-3138e019080b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = './'\n",
        "\n",
        "embeddings_index = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvtqPv6m0rV6"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim)) #create an array of zeros with word_num rows and embedding_dim columns\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < vocab_size:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnnsFvBT0h__",
        "outputId": "18522ece-ab49-40f9-8279-ca1db232574e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Build the modeling with Glove  Embedding Layer \n",
        "model_3 = Sequential()\n",
        "model_3.add(Embedding(vocab_size,embedding_dim , input_length = seq_length))\n",
        "model_3.add(LSTM(150 , return_sequences= True))\n",
        "model_3.add(Dropout(0.3))\n",
        "model_3.add(LSTM(100))\n",
        "model_3.add(Dense(100 , activation='relu'))\n",
        "model_3.add(Dense(vocab_size , activation= 'softmax'))\n",
        "print(model_3.summary())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 100, 100)          693600    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 100, 150)          150600    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 100)               100400    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 6936)              700536    \n",
            "=================================================================\n",
            "Total params: 1,655,236\n",
            "Trainable params: 1,655,236\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnbiBnAr3ELx"
      },
      "source": [
        "model_3.layers[0].set_weights([embedding_matrix])\n",
        "model_3.layers[0].trainable = False"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUJ0w31D3I4B",
        "outputId": "1b44b50a-3c27-4919-d968-008f87d0226e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_3.compile(loss='categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\n",
        "model_3.fit(X ,y , batch_size = 64 , epochs=100)  "
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 8.4343 - accuracy: 0.0053\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 2s 52ms/step - loss: 7.1577 - accuracy: 0.0189\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.9754 - accuracy: 0.0189\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.9296 - accuracy: 0.0189\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.9102 - accuracy: 0.0189\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8999 - accuracy: 0.0189\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8879 - accuracy: 0.0189\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8713 - accuracy: 0.0155\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8505 - accuracy: 0.0189\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8288 - accuracy: 0.0189\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.8072 - accuracy: 0.0185\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.7716 - accuracy: 0.0196\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.7023 - accuracy: 0.0226\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.5868 - accuracy: 0.0257\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.4758 - accuracy: 0.0294\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.3677 - accuracy: 0.0287\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 2s 47ms/step - loss: 6.2555 - accuracy: 0.0298\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 2s 47ms/step - loss: 6.1342 - accuracy: 0.0358\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 6.0106 - accuracy: 0.0396\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.8728 - accuracy: 0.0404\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.7433 - accuracy: 0.0411\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.6154 - accuracy: 0.0453\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.4831 - accuracy: 0.0494\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.3707 - accuracy: 0.0536\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.2643 - accuracy: 0.0517\n",
            "Epoch 26/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.1739 - accuracy: 0.0558\n",
            "Epoch 27/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.0851 - accuracy: 0.0589\n",
            "Epoch 28/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 5.0274 - accuracy: 0.0596\n",
            "Epoch 29/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 4.9356 - accuracy: 0.0600\n",
            "Epoch 30/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 4.8610 - accuracy: 0.0679\n",
            "Epoch 31/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.8051 - accuracy: 0.0657\n",
            "Epoch 32/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.7432 - accuracy: 0.0694\n",
            "Epoch 33/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.6686 - accuracy: 0.0717\n",
            "Epoch 34/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.5878 - accuracy: 0.0789\n",
            "Epoch 35/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.5358 - accuracy: 0.0808\n",
            "Epoch 36/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.4765 - accuracy: 0.0808\n",
            "Epoch 37/100\n",
            "42/42 [==============================] - 2s 47ms/step - loss: 4.4084 - accuracy: 0.0808\n",
            "Epoch 38/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.3346 - accuracy: 0.0913\n",
            "Epoch 39/100\n",
            "42/42 [==============================] - 2s 47ms/step - loss: 4.2843 - accuracy: 0.0891\n",
            "Epoch 40/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.2209 - accuracy: 0.0925\n",
            "Epoch 41/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.1458 - accuracy: 0.0962\n",
            "Epoch 42/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 4.0661 - accuracy: 0.1038\n",
            "Epoch 43/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.9942 - accuracy: 0.1075\n",
            "Epoch 44/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.9345 - accuracy: 0.1204\n",
            "Epoch 45/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.8668 - accuracy: 0.1200\n",
            "Epoch 46/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.7885 - accuracy: 0.1325\n",
            "Epoch 47/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.7077 - accuracy: 0.1328\n",
            "Epoch 48/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.6296 - accuracy: 0.1445\n",
            "Epoch 49/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.5485 - accuracy: 0.1577\n",
            "Epoch 50/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.4673 - accuracy: 0.1642\n",
            "Epoch 51/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.3921 - accuracy: 0.1792\n",
            "Epoch 52/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.3123 - accuracy: 0.1883\n",
            "Epoch 53/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.2561 - accuracy: 0.1932\n",
            "Epoch 54/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.1616 - accuracy: 0.2196\n",
            "Epoch 55/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.0894 - accuracy: 0.2287\n",
            "Epoch 56/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 3.0397 - accuracy: 0.2317\n",
            "Epoch 57/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.9529 - accuracy: 0.2483\n",
            "Epoch 58/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.8989 - accuracy: 0.2706\n",
            "Epoch 59/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.8421 - accuracy: 0.2577\n",
            "Epoch 60/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.7561 - accuracy: 0.2875\n",
            "Epoch 61/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.7316 - accuracy: 0.2906\n",
            "Epoch 62/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.6552 - accuracy: 0.3091\n",
            "Epoch 63/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.6129 - accuracy: 0.3147\n",
            "Epoch 64/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.5415 - accuracy: 0.3491\n",
            "Epoch 65/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.4864 - accuracy: 0.3491\n",
            "Epoch 66/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.4222 - accuracy: 0.3611\n",
            "Epoch 67/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.3584 - accuracy: 0.3891\n",
            "Epoch 68/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.3230 - accuracy: 0.3849\n",
            "Epoch 69/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.2575 - accuracy: 0.4075\n",
            "Epoch 70/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.2211 - accuracy: 0.3958\n",
            "Epoch 71/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.1700 - accuracy: 0.4294\n",
            "Epoch 72/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.1082 - accuracy: 0.4502\n",
            "Epoch 73/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.0789 - accuracy: 0.4506\n",
            "Epoch 74/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 2.0026 - accuracy: 0.4679\n",
            "Epoch 75/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.9433 - accuracy: 0.4913\n",
            "Epoch 76/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.9109 - accuracy: 0.4996\n",
            "Epoch 77/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.8656 - accuracy: 0.5117\n",
            "Epoch 78/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.8204 - accuracy: 0.5158\n",
            "Epoch 79/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.7650 - accuracy: 0.5328\n",
            "Epoch 80/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.7326 - accuracy: 0.5389\n",
            "Epoch 81/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.7028 - accuracy: 0.5487\n",
            "Epoch 82/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.6329 - accuracy: 0.5638\n",
            "Epoch 83/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.5895 - accuracy: 0.5785\n",
            "Epoch 84/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.5519 - accuracy: 0.5906\n",
            "Epoch 85/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.5321 - accuracy: 0.5966\n",
            "Epoch 86/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.5018 - accuracy: 0.6106\n",
            "Epoch 87/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.4489 - accuracy: 0.6143\n",
            "Epoch 88/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.3864 - accuracy: 0.6415\n",
            "Epoch 89/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.3550 - accuracy: 0.6543\n",
            "Epoch 90/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.3213 - accuracy: 0.6498\n",
            "Epoch 91/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.2907 - accuracy: 0.6653\n",
            "Epoch 92/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.2551 - accuracy: 0.6736\n",
            "Epoch 93/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.1979 - accuracy: 0.6917\n",
            "Epoch 94/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.1851 - accuracy: 0.6894\n",
            "Epoch 95/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.1412 - accuracy: 0.7042\n",
            "Epoch 96/100\n",
            "42/42 [==============================] - 2s 45ms/step - loss: 1.1209 - accuracy: 0.7132\n",
            "Epoch 97/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.0715 - accuracy: 0.7192\n",
            "Epoch 98/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.0540 - accuracy: 0.7340\n",
            "Epoch 99/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 1.0285 - accuracy: 0.7415\n",
            "Epoch 100/100\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 0.9928 - accuracy: 0.7483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1dd0162dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF3y3Z2G9wW6"
      },
      "source": [
        "# The accuracy is  high , I think so model is overfitting!!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTRUtZDA3Bve"
      },
      "source": [
        "def generate_seq_3(model , tokenizer , seq_length , seed_text , n_words):\n",
        "  result = list()\n",
        "  for _ in range(n_words):\n",
        "    #s\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre' , padding = 'pre')\n",
        "    y_pred = model_3.predict_classes(encoded , verbose=0)\n",
        "    out_word = ''\n",
        "    for word ,index in tokenizer.word_index.items():\n",
        "      if index == y_pred:\n",
        "        out_word = word\n",
        "        break\n",
        "    seed_text += ' '+out_word\n",
        "    result.append(out_word)\n",
        "  return ' '.join(result) "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzJS27-P3RdV",
        "outputId": "ba5533c9-ef2b-4f3a-f955-93120a52fe0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "seed_text = tokens[random.randint(0,len(tokens))]\n",
        "#seed_text = 'There was once upon a time , when Britishers ruled India'\n",
        "print(seed_text + '\\n')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " there was a man with his wife and two boys and some articles of furniture in a cart such as greengrocers use\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApXkorFT3RU8",
        "outputId": "301d4d8a-c1c2-420e-d3e3-1d7016aafee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "generated_text = generate_seq_3(model , tokenizer , seq_length , seed_text , 50)\n",
        "print(seed_text + ' -> ' +  generated_text)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " there was a man with his wife and two boys and some articles of furniture in a cart such as greengrocers use -> hearts mine settled it mouth again killed horses gave them emptied restored miles us ruin another oclock beneath star it lay together immune conviction more days days days ago dead days be all out on me garden house house clearly forth over me garden house windows wanted on them hours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTEC895-AmaW"
      },
      "source": [
        "# Build the model Without Glove Embedding Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACtBY2qUe9Vx",
        "outputId": "623fc5f6-303f-46b0-fe55-358a0992fe25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,50 , input_length=seq_length))\n",
        "model.add(LSTM(150 , return_sequences= True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(100 , activation='relu'))\n",
        "model.add(Dense(vocab_size , activation= 'softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           346800    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100, 150)          120600    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 150)               180600    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6936)              700536    \n",
            "=================================================================\n",
            "Total params: 1,363,636\n",
            "Trainable params: 1,363,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_VzazlefUjt",
        "outputId": "aa6ca964-9aff-495e-cfcb-5c9264509fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy' , optimizer = 'adam')\n",
        "model.fit(X ,y , batch_size = 64 , epochs=100)  "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 3s 67ms/step - loss: 8.4039\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 3s 62ms/step - loss: 7.2200\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 3s 62ms/step - loss: 7.0072\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 3s 61ms/step - loss: 6.9409\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 3s 60ms/step - loss: 6.9144\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 3s 60ms/step - loss: 6.9010\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 2s 59ms/step - loss: 6.8988\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 2s 59ms/step - loss: 6.8857\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.8766\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.8277\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.7623\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.7041\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.6416\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.5689\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 6.4490\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.2777\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 6.1019\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.9432\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.7930\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 5.6380\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.4950\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.3682\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.2254\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.1300\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 5.0154\n",
            "Epoch 26/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.8877\n",
            "Epoch 27/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.7661\n",
            "Epoch 28/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.6791\n",
            "Epoch 29/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.5682\n",
            "Epoch 30/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 4.4441\n",
            "Epoch 31/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 4.3245\n",
            "Epoch 32/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.2159\n",
            "Epoch 33/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 4.1074\n",
            "Epoch 34/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 4.0110\n",
            "Epoch 35/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.9177\n",
            "Epoch 36/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.8214\n",
            "Epoch 37/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.7365\n",
            "Epoch 38/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.6317\n",
            "Epoch 39/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 3.5427\n",
            "Epoch 40/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.4644\n",
            "Epoch 41/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.3612\n",
            "Epoch 42/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 3.2809\n",
            "Epoch 43/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.2030\n",
            "Epoch 44/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 3.1270\n",
            "Epoch 45/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 3.0721\n",
            "Epoch 46/100\n",
            "42/42 [==============================] - 2s 59ms/step - loss: 2.9868\n",
            "Epoch 47/100\n",
            "42/42 [==============================] - 2s 59ms/step - loss: 2.9023\n",
            "Epoch 48/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.8113\n",
            "Epoch 49/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.7625\n",
            "Epoch 50/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.6889\n",
            "Epoch 51/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.6230\n",
            "Epoch 52/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.5807\n",
            "Epoch 53/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 2.5011\n",
            "Epoch 54/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.4316\n",
            "Epoch 55/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 2.3739\n",
            "Epoch 56/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.3088\n",
            "Epoch 57/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.2573\n",
            "Epoch 58/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.1848\n",
            "Epoch 59/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.1275\n",
            "Epoch 60/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.0686\n",
            "Epoch 61/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 2.0267\n",
            "Epoch 62/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.9764\n",
            "Epoch 63/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.9258\n",
            "Epoch 64/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.8809\n",
            "Epoch 65/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.8518\n",
            "Epoch 66/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.7938\n",
            "Epoch 67/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.7425\n",
            "Epoch 68/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.6926\n",
            "Epoch 69/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.6298\n",
            "Epoch 70/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.5717\n",
            "Epoch 71/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.5199\n",
            "Epoch 72/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.4880\n",
            "Epoch 73/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.4581\n",
            "Epoch 74/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.4298\n",
            "Epoch 75/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.3449\n",
            "Epoch 76/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.2947\n",
            "Epoch 77/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.2652\n",
            "Epoch 78/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.2271\n",
            "Epoch 79/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.1876\n",
            "Epoch 80/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.1527\n",
            "Epoch 81/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.1171\n",
            "Epoch 82/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.0844\n",
            "Epoch 83/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 1.0475\n",
            "Epoch 84/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 1.0217\n",
            "Epoch 85/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.9976\n",
            "Epoch 86/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.9655\n",
            "Epoch 87/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.9338\n",
            "Epoch 88/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 0.8881\n",
            "Epoch 89/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.8704\n",
            "Epoch 90/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.8284\n",
            "Epoch 91/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.8032\n",
            "Epoch 92/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.8013\n",
            "Epoch 93/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.7598\n",
            "Epoch 94/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.7105\n",
            "Epoch 95/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 0.6639\n",
            "Epoch 96/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.6336\n",
            "Epoch 97/100\n",
            "42/42 [==============================] - 2s 58ms/step - loss: 0.6141\n",
            "Epoch 98/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 0.5891\n",
            "Epoch 99/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 0.5993\n",
            "Epoch 100/100\n",
            "42/42 [==============================] - 2s 57ms/step - loss: 0.6355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1de62fdda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBaBXVuEfZne"
      },
      "source": [
        "def generate_seq(model , tokenizer , seq_length , seed_text , n_words):\n",
        "  result = list()\n",
        "  for _ in range(n_words):\n",
        "    #s\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre' , padding = 'pre')\n",
        "    y_pred = model.predict_classes(encoded , verbose=0)\n",
        "    out_word = ''\n",
        "    for word ,index in tokenizer.word_index.items():\n",
        "      if index == y_pred:\n",
        "        out_word = word\n",
        "        break\n",
        "    seed_text += ' '+out_word\n",
        "    result.append(out_word)\n",
        "  return ' '.join(result) "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLihakz-fhrc",
        "outputId": "e15afd2d-5a38-4ce1-9528-ebdd77f3bb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "seed_text = tokens[random.randint(0,len(tokens))]\n",
        "#seed_text = 'There was once upon a time , when Britishers ruled India'\n",
        "print(seed_text + '\\n')\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " already men weeping with joy as i have heard shouting and staying their work to shake hands and shout were making up trains even as near as crewe to descend upon london\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYX7w1SJe9Eg",
        "outputId": "0a153761-94b0-4a22-e817-2ba662257675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "generated_text = generate_seq(model , tokenizer , seq_length , seed_text , 50)\n",
        "print(seed_text + ' ' +  generated_text)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " already men weeping with joy as i have heard shouting and staying their work to shake hands and shout were making up trains even as near as crewe to descend upon london common creeper day rose forethought nearer bear another position packages brightly days days energy tone punch solitude shivering monstrous guns worry carriages quality empty shivering scalded scalded scalded scalded dead days it fro ago there itself dead doors upward yet killed desolate apathy days days days days two days days\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YZ3yH2nb82Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX-Cbm53cmPP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOgWmAx6X7uc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4xY9CQX2N4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt5Ge54sXWu6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOVqU-zPWcIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H08s9QvfsK7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx50srXXahKK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_nSPA9safH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}